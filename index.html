<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Apoorv Vyas</title>

  <meta name="author" content="Apoorv Vyas">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Apoorv Vyas</name>
              </p>
              <p>
                Hello! I am Apoorv Vyas, currently a Ph.D. student at <a
                href=https://www.epfl.ch/en/>EPFL</a>, and research assistant in
                <a
                href="https://www.idiap.ch/en/scientific-research/speech-and-audio-processing">
                Speech and Audio Processing </a> at <a
                href="https://www.idiap.ch/en">Idiap Research Institute</a>
                under the joint supervision of <a
                href=https://people.idiap.ch/bourlard>Prof. Hervé Bourlard</a>
                and <a href=https://fleuret.org/francois/>Prof. François
                Fleuret</a>.
              </p>
              <p>
                Prior to joining Idiap, I received my Bachelor's in Electrical
                Engineering from <a href="http://www.iitg.ac.in/">Indian
                Institute of Technology Guwahati</a>.  After which I joined
                Intel Labs (Bangalore) where I worked on <em>Compressed
                Sensing</em> for power-efficient communications in body sensor
                networks and wireless sensor networks. I also worked on
                detecting out-of-distribution input to a deep neural network.
              </p>
              <p style="text-align:center">
                <a href="mailto:apoorv.vyas@idiap.ch">Email</a> &nbsp/&nbsp
                <a href="data/ApoorvVyas-CV-Apr-2022.pdf">CV</a> &nbsp/&nbsp
                <!--<a href="data/ApoorvVyas-bio.txt">Biography</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.co.in/citations?user=7EoDBR0AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/apoorv2904">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/apoorv2904">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/apoorv2904">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
                <!--<a href="images/ApoorvVyas-circle.png"><img-->
              <a href="images/ApoorvVyas-circle-2.png"><img
                style="width:100%;max-width:100%"
                alt="profile photo"
                src="images/ApoorvVyas-circle-2.png"
                class="hoverZoomLink">
              </a>
            </td>
          </tr>
        </tbody></table>

        <!--table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr style="padding:0px">
            <td style="padding-left:2.5%; padding-top:0.5%; width:100%;vertical-align:middle; background-color:#FFFFE0">
                <p>
                    Expected gradutation in July 2022. Looking for summer research internship in 2021.
                </p>
            </td>
            </tr>
          </tbody>
        </table-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;padding-bottom:0px;width:100%;vertical-align:middle">
                <heading>Research</heading>
                <p>
                  I am interested in machine learning,
                  speech recognition, and computer vision.
                </p>
                <p>
                  The goal of my Ph.D is to improve the performance of
                  end-to-end automatic speech recognition (ASR) models with a
                  special focus on the low to medium resource datasets.
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:20px;padding-bottom:20px;width:100%;vertical-align:middle">
                <heading>Publications</heading>
              </td>
            </tr>
          </tbody>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/wav2vec2.JPG' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Comparing CTC and LFMMI for Out-of-Domain Adaptation of Wav2vec 2.0 Acoustic Model
              </papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              <a href="https://www.idiap.ch/~msrikanth/">S. Madikeri</a>,
              <a href="https://people.idiap.ch/bourlard">H. Bourlard</a>,
              </div>
              <em>Interspeech </em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2104.02558.pdf">paper</a>
              <!--a href="https://github.com/idiap/apam">code</a> /-->
              <!--a href="https://idiap.ch/~avyas/bib/arxiv-2020-lfmmi.txt">bibtex</a-->
              <p></p>
              <p>
                Comparing sequence discriminative criterion for adaptation of wav2vec 2.0 model.
              </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/arxiv_2020_lfmmi.JPG' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Lattice-Free MMI Adaptation of Self-Supervised Pretrained Acoustic Models
              </papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              <a href="https://www.idiap.ch/~msrikanth/">S. Madikeri</a>,
              <a href="https://people.idiap.ch/bourlard">H. Bourlard</a>,
              </div>
              <em>ICASSP</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2012.14252.pdf">paper</a> /
              <a href="https://github.com/idiap/apam">code</a> /
              <a href="https://idiap.ch/~avyas/bib/arxiv-2020-lfmmi.txt">bibtex</a>
              <p></p>
              <p>
                Using MMI loss to adapt pre-trained acoustic models to low resource datasets.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/neurips_2020_fast.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Fast Transformers with Clustered Attention</papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              <a href="https://angeloskath.github.io/">A. Katharopoulos</a>,
              <a href="https://fleuret.org/francois/">F. Fleuret</a>,
              </div>
              <em>NeurIPS</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2007.04825.pdf">paper</a> /
              <a href="https://idiap.ch/~avyas/pdfs/poster-neurips-2020.pdf">poster</a> /
              <a href="https://clustered-transformers.github.io/blog">blog</a> /
              <a href="https://colab.research.google.com/drive/1E8BYQf3Puxb643LOyIjT-0m3yXGO28ev?usp=sharing">
              colab</a> /
              <a href="https://github.com/idiap/fast-transformers">code</a> /
              <a href="https://idiap.ch/~avyas/bib/neurips-2020.txt">bibtex</a>
              <p></p>
              <p>
                Scaling Attention to long sequences by clustering queries.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/icml_2020_transformers.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Transformers are RNNs: Fast Autoregressive
                Transformers with Linear Attention</papertitle>
              <br>
              <div class=author>
              <a href="https://angeloskath.github.io/">A. Katharopoulos</a>,
              <strong>A. Vyas</strong>,
              <a href="https://https://nik0spapp.github.io/">N. pappas</a>,
              <a href="https://fleuret.org/francois/">F. Fleuret</a>,
              </div>
              <em>ICML</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2006.16236.pdf">paper</a> /
              <a href="https://youtu.be/KBWh7XCUAi8">video</a> /
              <a href="https://idiap.ch/~katharas/pdfs/linear-transformers-slides.pdf">slides</a> /
              <a href="https://colab.research.google.com/drive/1BV4OaWRAHYGeimO0cqHD86GfnfgUaKD4?usp=sharing">
              colab</a> /
              <a href="https://github.com/idiap/fast-transformers">code</a> /
              <a href="https://idiap.ch/~avyas/bib/icml-2020.txt">bibtex</a>
              <p></p>
              <p>
                Scaling Attention to long sequences with kernelized linear attention.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/tbd.png' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Pkwrap: a PyTorch Package for LF-MMI Training of Acoustic Models
              </papertitle>
              <br>
              <div class=author>
              <a href="https://www.idiap.ch/~msrikanth/">S. Madikeri</a>,
              S. Tong,
              J. GOMEZ,
              <strong>A. Vyas</strong>,
              <a href="https://www.idiap.ch/~pmotlic/">P. Motlic</a>,
              <a href="https://people.idiap.ch/bourlard">H. Bourlard</a>,
              </div>
              <em>arXiv</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2010.03466.pdf">paper</a> /
              <a href="https://github.com/idiap/pkwrap">code</a> /
              <a href="https://idiap.ch/~avyas/bib/arxiv-2020-pkwrap.txt">bibtex</a>
              <p></p>
              <p>
                PyTorch package to expose Kaldi functionalities and LF-MMI loss
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/interspeech_2019_unbiassed.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Unbiased Semi-supervised LF-MMI Training Using Dropout</papertitle>
              <br>
              <div class=author>
              S. Tong,
              <strong>A. Vyas</strong>,
              <a href="https://pgarner.github.io/">P. Garner</a>,
              <a href="https://people.idiap.ch/bourlard">H. Bourlard</a>,
              </div>
              <em>Interspeech</em>, 2019
              <br>
              <a href="https://www.isca-speech.org/archive/Interspeech_2019/pdfs/2678.pdf">paper</a> /
              <a href="https://idiap.ch/~avyas/pdfs/poster-interspeech-2019.pdf">poster</a> /
              <a href="https://idiap.ch/~avyas/bib/interspeech-2019.txt">bibtex</a>
              <p></p>
              <p>
                Semisupervised Training by combining multiple hypotheses with Dropout.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/icassp_2019_analyzing.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Analyzing Uncertainties in Speech Recognition Using Dropout</papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              <a href=" https://sites.google.com/site/pranaydighehomepage/">P. Dighe</a>,
              S. Tong,
              <a href="https://people.idiap.ch/bourlard">H. Bourlard</a>,
              </div>
              <em>ICASSP</em>, 2019
              <br>
              <a href="https://ieeexplore.ieee.org/document/8683086">paper</a> /
              <a href="https://idiap.ch/~avyas/pdfs/poster-icassp-2019.pdf">poster</a> /
              <a href="https://idiap.ch/~avyas/bib/icassp-2019.txt">bibtex</a>
              <p></p>
              <p>
                Unsupervised word error rate estimation by analyzing multiple hypotheses with Dropout.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/eccv_2018_ood.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out Classifiers</papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              N. Jammalamadaka, X. Zhu, D. Das, B. Kaul, T. Willke
              </div>
              <em>ECCV</em>, 2018
              <br>
              <a href="https://arxiv.org/pdf/1809.03576.pdf">paper</a> /
              <a href="https://idiap.ch/~avyas/pdfs/poster-eccv-2018.pdf">poster</a> /
              <a href="https://idiap.ch/~avyas/bib/eccv-2018.txt">bibtex</a>
              <p></p>
              <p>
                Detecting out-of-distribution input by entropy maximization.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/wfiot_2016_cs.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Power Efficient Compressive Sensing for Continuous Monitoring of ECG and PPG in a Wearable System</papertitle>
              <br>
              <div class=author>
              V. Natarajan,
              <strong>A. Vyas</strong>,
              </div>
              <em>WFIOT</em>, 2016
              <br>
              <a href="http://ieeexplore.ieee.org/document/7845493">paper</a> /
              <a href="https://idiap.ch/~avyas/bib/wfiot-2016.txt">bibtex</a>
              <p></p>
              <p>
                Using compressive sensing for energy efficient signal acquisition and denoising on wearable devices.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/icvgip_2014_commercial.jpg' width="200px">
            </td>
            <td style="padding-left:20px;width:75%;vertical-align:middle">
              <papertitle>Commercial Block Detection in Broadcast News Videos</papertitle>
              <br>
              <div class=author>
              <strong>A. Vyas</strong>,
              R. Kannao,
              V. Bhargava,
              <a href=https://www.iitg.ac.in/eee/pguha.html>P. Guha</a>
              </div>
              <em>ICVGIP</em>, 2014
              <br>
              <a href="https://idiap.ch/~avyas/pdfs/icvgip-2014.pdf">paper</a> /
              <a href="https://idiap.ch/~avyas/bib/icvgip-2014.txt">bibtex</a>
              <p></p>
              <p>
                Detecting commercials in TV News using hand-crafted features and SVM.
              </p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding-right:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                 Thanks to <a href="https://jonbarron.info/">Jon Barron</a> for the template.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
